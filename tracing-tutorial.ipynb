{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TriageFlow: Incident Triage Demo\n",
    "\n",
    "Multi-agent incident triage with Domino GenAI tracing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Save your API key as a Domino user environment variable:\n",
    "1. **Account Settings** → **User Environment Variables**\n",
    "2. Add `OPENAI_API_KEY` or `ANTHROPIC_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import sys\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Provider & Vertical\n",
    "\n",
    "Choose your LLM provider and industry vertical for sample incidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e9ec31d1ea643329ddb910952b21ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Provider:', options=('openai', 'anthropic'), value='openai')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98029a1edd904b249ffc6476e1f21f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Vertical:', options=(('Financial Services', 'financial_services'), ('Healthcare', 'healt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "provider_dropdown = widgets.Dropdown(\n",
    "    options=[\"openai\", \"anthropic\"],\n",
    "    value=\"openai\",\n",
    "    description=\"Provider:\"\n",
    ")\n",
    "\n",
    "vertical_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"Financial Services\", \"financial_services\"),\n",
    "        (\"Healthcare\", \"healthcare\"),\n",
    "        (\"Energy\", \"energy\"),\n",
    "        (\"Public Sector\", \"public_sector\")\n",
    "    ],\n",
    "    value=\"financial_services\",\n",
    "    description=\"Vertical:\"\n",
    ")\n",
    "\n",
    "display(provider_dropdown, vertical_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "All prompts, model settings, and agent parameters are centralized in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: openai\n",
      "Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "provider = provider_dropdown.value\n",
    "model = config[\"models\"][provider]\n",
    "print(f\"Provider: {provider}\\nModel: {model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Client & Auto-Tracing\n",
    "\n",
    "MLflow's `autolog()` automatically captures all LLM calls without additional instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-tracing enabled for openai\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Disable inline trace display in notebook\n",
    "mlflow.tracing.disable_notebook_display()\n",
    "\n",
    "if provider == \"openai\":\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    mlflow.openai.autolog()\n",
    "else:\n",
    "    from anthropic import Anthropic\n",
    "    client = Anthropic()\n",
    "    mlflow.anthropic.autolog()\n",
    "\n",
    "print(f\"Auto-tracing enabled for {provider}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Domino Tracing\n",
    "\n",
    "- `add_tracing`: Decorator for capturing inputs, outputs, and evaluation metrics\n",
    "- `DominoRun`: Context manager for aggregating metrics across multiple traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from domino.agents.tracing import add_tracing\n",
    "from domino.agents.logging import DominoRun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models, Agents, and Judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import Incident, IncidentSource\n",
    "from src.agents import classify_incident, assess_impact, match_resources, draft_response\n",
    "from src.judges import judge_classification, judge_response, judge_triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_evaluator(span) -> dict:\n",
    "    \"\"\"Extract pre-computed metrics from pipeline outputs.\"\"\"\n",
    "    outputs = span.outputs or {}\n",
    "    if not hasattr(outputs, \"get\"):\n",
    "        return {}\n",
    "\n",
    "    # Scores are pre-computed inside triage_incident\n",
    "    return {\n",
    "        \"classification_confidence\": outputs.get(\"classification_confidence\", 0.5),\n",
    "        \"impact_score\": outputs.get(\"impact_score\", 5.0),\n",
    "        \"resource_match_score\": outputs.get(\"resource_match_score\", 0.5),\n",
    "        \"completeness_score\": outputs.get(\"completeness_score\", 0.5),\n",
    "        \"classification_judge_score\": outputs.get(\"classification_judge_score\", 3),\n",
    "        \"response_judge_score\": outputs.get(\"response_judge_score\", 3),\n",
    "        \"triage_judge_score\": outputs.get(\"triage_judge_score\", 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Traced Pipeline\n",
    "\n",
    "The `@add_tracing` decorator creates a single trace tree per incident. Each agent runs as a nested span with:\n",
    "- Function inputs and outputs\n",
    "- LLM calls captured via autolog (showing span types like `ChatCompletion`)\n",
    "- Evaluation metrics attached to the trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "@add_tracing(name=\"triage_incident\", autolog_frameworks=[provider], evaluator=pipeline_evaluator)\n",
    "def triage_incident(incident: Incident):\n",
    "    \"\"\"Run the 4-agent triage pipeline with LLM judges.\"\"\"\n",
    "    # Run agents\n",
    "    classification = classify_incident(client, provider, model, incident, config)\n",
    "    impact = assess_impact(client, provider, model, incident, classification, config)\n",
    "    resources = match_resources(client, provider, model, classification, impact, config)\n",
    "    response = draft_response(client, provider, model, incident, classification, impact, resources, config)\n",
    "\n",
    "    # Convert to dicts for judges\n",
    "    class_dict = classification.model_dump()\n",
    "    impact_dict = impact.model_dump()\n",
    "    resources_dict = resources.model_dump()\n",
    "    response_dict = response.model_dump()\n",
    "    primary = resources_dict.get(\"primary_responder\", {})\n",
    "\n",
    "    # Run judges inside trace context (updated signatures include model parameter)\n",
    "    class_judge = judge_classification(client, provider, model, incident.description, class_dict)\n",
    "    \n",
    "    # judge_response now returns a list of evaluations\n",
    "    resp_judges = judge_response(client, provider, model, incident.description, response_dict)\n",
    "    if resp_judges:\n",
    "        resp_judge = {\"score\": sum(r.get(\"score\", 3) for r in resp_judges) / len(resp_judges)}\n",
    "    else:\n",
    "        resp_judge = {\"score\": 3}\n",
    "    \n",
    "    # judge_triage now takes a combined triage_output dict\n",
    "    triage_output = {\n",
    "        \"classification\": class_dict,\n",
    "        \"impact\": impact_dict,\n",
    "        \"assignment\": resources_dict,\n",
    "        \"response\": response_dict\n",
    "    }\n",
    "    triage_judge = judge_triage(client, provider, model, incident.description, triage_output)\n",
    "\n",
    "    return {\n",
    "        \"classification\": classification,\n",
    "        \"impact\": impact,\n",
    "        \"resources\": resources,\n",
    "        \"response\": response,\n",
    "        # Metrics for evaluator\n",
    "        \"classification_confidence\": class_dict.get(\"confidence\", 0.5),\n",
    "        \"impact_score\": impact_dict.get(\"impact_score\", 5.0),\n",
    "        \"resource_match_score\": primary.get(\"match_score\", 0.5) if isinstance(primary, dict) else 0.5,\n",
    "        \"completeness_score\": response_dict.get(\"completeness_score\", 0.5),\n",
    "        \"classification_judge_score\": class_judge.get(\"score\", 3),\n",
    "        \"response_judge_score\": resp_judge.get(\"score\", 3),\n",
    "        \"triage_judge_score\": triage_judge.get(\"score\", 3),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sample Incidents\n",
    "\n",
    "Example incidents will be loaded from the vertical selected above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 incidents from financial_services\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticket_id</th>\n",
       "      <th>description</th>\n",
       "      <th>source</th>\n",
       "      <th>reporter</th>\n",
       "      <th>affected_system</th>\n",
       "      <th>initial_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FIN-2024-001</td>\n",
       "      <td>Trading platform experiencing intermittent ord...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trading Platform</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FIN-2024-002</td>\n",
       "      <td>Suspicious login attempts detected on wire tra...</td>\n",
       "      <td>automated_scan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wire Transfer System</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FIN-2024-003</td>\n",
       "      <td>End-of-day reconciliation report shows $2.3M d...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Settlement System</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIN-2024-004</td>\n",
       "      <td>Customer mobile app crash rate spiked to 12% a...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>App Support Team</td>\n",
       "      <td>Mobile Banking App</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FIN-2024-005</td>\n",
       "      <td>SWIFT message queue backlog growing. Currently...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWIFT Gateway</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FIN-2024-006</td>\n",
       "      <td>Fraud detection system generating excessive fa...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>Fraud Ops Team</td>\n",
       "      <td>Fraud Detection Engine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FIN-2024-007</td>\n",
       "      <td>Market data feed from Bloomberg showing stale ...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Market Data Feed</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FIN-2024-008</td>\n",
       "      <td>ATM network in midwest region offline. 127 ATM...</td>\n",
       "      <td>user_report</td>\n",
       "      <td>ATM Operations</td>\n",
       "      <td>ATM Network</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FIN-2024-009</td>\n",
       "      <td>Regulatory report CCAR-2024-Q4 generation fail...</td>\n",
       "      <td>monitoring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Risk Analytics Platform</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FIN-2024-010</td>\n",
       "      <td>Customer PII potentially exposed via misconfig...</td>\n",
       "      <td>automated_scan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Customer API Gateway</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ticket_id                                        description  \\\n",
       "0  FIN-2024-001  Trading platform experiencing intermittent ord...   \n",
       "1  FIN-2024-002  Suspicious login attempts detected on wire tra...   \n",
       "2  FIN-2024-003  End-of-day reconciliation report shows $2.3M d...   \n",
       "3  FIN-2024-004  Customer mobile app crash rate spiked to 12% a...   \n",
       "4  FIN-2024-005  SWIFT message queue backlog growing. Currently...   \n",
       "5  FIN-2024-006  Fraud detection system generating excessive fa...   \n",
       "6  FIN-2024-007  Market data feed from Bloomberg showing stale ...   \n",
       "7  FIN-2024-008  ATM network in midwest region offline. 127 ATM...   \n",
       "8  FIN-2024-009  Regulatory report CCAR-2024-Q4 generation fail...   \n",
       "9  FIN-2024-010  Customer PII potentially exposed via misconfig...   \n",
       "\n",
       "           source          reporter          affected_system  initial_severity  \n",
       "0      monitoring               NaN         Trading Platform                 5  \n",
       "1  automated_scan               NaN     Wire Transfer System                 5  \n",
       "2      monitoring               NaN        Settlement System                 4  \n",
       "3     user_report  App Support Team       Mobile Banking App                 3  \n",
       "4      monitoring               NaN            SWIFT Gateway                 4  \n",
       "5     user_report    Fraud Ops Team   Fraud Detection Engine                 3  \n",
       "6      monitoring               NaN         Market Data Feed                 4  \n",
       "7     user_report    ATM Operations              ATM Network                 4  \n",
       "8      monitoring               NaN  Risk Analytics Platform                 3  \n",
       "9  automated_scan               NaN     Customer API Gateway                 5  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vertical = vertical_dropdown.value\n",
    "df = pd.read_csv(f\"example-data/{vertical}.csv\")\n",
    "print(f\"Loaded {len(df)} incidents from {vertical}\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 incidents\n"
     ]
    }
   ],
   "source": [
    "def row_to_incident(row) -> Incident:\n",
    "    return Incident(\n",
    "        ticket_id=row[\"ticket_id\"],\n",
    "        description=row[\"description\"],\n",
    "        source=IncidentSource(row[\"source\"]),\n",
    "        reporter=row[\"reporter\"] if pd.notna(row[\"reporter\"]) else None,\n",
    "        affected_system=row[\"affected_system\"] if pd.notna(row[\"affected_system\"]) else None,\n",
    "        initial_severity=int(row[\"initial_severity\"]) if pd.notna(row[\"initial_severity\"]) else None\n",
    "    )\n",
    "\n",
    "incidents = [row_to_incident(row) for _, row in df.iterrows()]\n",
    "print(f\"Loaded {len(incidents)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Triage Pipeline\n",
    "\n",
    "`DominoRun` aggregates metrics across all traces in the batch via `custom_summary_metrics`. Supported aggregations: `mean`, `median`, `stdev`, `min`, `max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: tracing-TriageFlow-GenAI-Tracing-andrea_lowe\n",
      "Run: financial_services-andrea_lowe-20260222-005606\n"
     ]
    }
   ],
   "source": [
    "# Experiment and run naming\n",
    "username = os.environ.get(\"DOMINO_USER_NAME\", os.environ.get(\"USER\", \"demo_user\"))\n",
    "project_name = os.environ.get(\"DOMINO_PROJECT_NAME\", \"default\")\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "experiment_name = f\"tracing-{project_name}-{username}\"\n",
    "run_name = f\"{vertical}-{username}-{timestamp}\"\n",
    "\n",
    "aggregated_metrics = [\n",
    "    # Base metrics\n",
    "    (\"classification_confidence\", \"mean\"),\n",
    "    (\"impact_score\", \"median\"),\n",
    "    (\"resource_match_score\", \"mean\"),\n",
    "    (\"completeness_score\", \"mean\"),\n",
    "    # Judge scores\n",
    "    (\"classification_judge_score\", \"mean\"),\n",
    "    (\"response_judge_score\", \"mean\"),\n",
    "    (\"triage_judge_score\", \"mean\"),\n",
    "]\n",
    "\n",
    "print(f\"Experiment: {experiment_name}\")\n",
    "print(f\"Run: {run_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing FIN-2024-001...\n",
      "  → performance | Urgency: 4 | Impact: 5.5\n",
      "Processing FIN-2024-002...\n",
      "  → security | Urgency: 5 | Impact: 7.5\n",
      "Processing FIN-2024-003...\n"
     ]
    }
   ],
   "source": [
    "# Set MLflow experiment\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "results = []\n",
    "run_id = None\n",
    "\n",
    "with DominoRun(agent_config_path=\"config.yaml\", custom_summary_metrics=aggregated_metrics) as run:\n",
    "    # Set run name via MLflow\n",
    "    mlflow.set_tag(\"mlflow.runName\", run_name)\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    for incident in incidents:\n",
    "        print(f\"Processing {incident.ticket_id}...\")\n",
    "        \n",
    "        result = triage_incident(incident)\n",
    "        \n",
    "        results.append({\n",
    "            \"ticket_id\": incident.ticket_id,\n",
    "            **result\n",
    "        })\n",
    "        print(f\"  → {result['classification'].category.value} | Urgency: {result['classification'].urgency} | Impact: {result['impact'].impact_score}\")\n",
    "    \n",
    "    # Suppress DominoRun exit messages\n",
    "    _stdout = sys.stdout\n",
    "    sys.stdout = io.StringIO()\n",
    "\n",
    "sys.stdout = _stdout\n",
    "print(f\"\\nProcessed {len(results)} incidents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame([{\n",
    "    \"Ticket\": r[\"ticket_id\"],\n",
    "    \"Category\": r[\"classification\"].category.value,\n",
    "    \"Urgency\": r[\"classification\"].urgency,\n",
    "    \"Impact\": r[\"impact\"].impact_score,\n",
    "    \"Responder\": r[\"resources\"].primary_responder.name,\n",
    "    \"SLA Met\": r[\"resources\"].sla_met\n",
    "} for r in results])\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Communication\n",
    "\n",
    "Each incident generates tailored communications for technical teams, management, and affected users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = results[0]\n",
    "print(f\"Ticket: {sample['ticket_id']}\\n\")\n",
    "for comm in sample[\"response\"].communications:\n",
    "    print(f\"--- {comm.audience.upper()} ---\")\n",
    "    print(f\"Subject: {comm.subject}\")\n",
    "    print(f\"{comm.body[:300]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad Hoc Evaluations\n",
    "\n",
    "Add evaluations after traces are generated using `search_traces()` to retrieve traces from the run and `log_evaluation()` to attach scores to specific traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from domino.aisystems.tracing import search_traces, log_evaluation\n",
    "from domino.agents.tracing import search_traces\n",
    "from domino.agents.logging import log_evaluation\n",
    "\n",
    "\n",
    "# Retrieve all traces from the run\n",
    "traces = search_traces(run_id=run_id)\n",
    "\n",
    "# Add custom evaluations to each trace based on triage results\n",
    "for i, trace in enumerate(traces.data):\n",
    "    result = results[i]\n",
    "    \n",
    "    # Compute combined quality score from judge evaluations\n",
    "    combined_quality = (\n",
    "        result[\"classification_judge_score\"] +\n",
    "        result[\"response_judge_score\"] +\n",
    "        result[\"triage_judge_score\"]\n",
    "    ) / 3\n",
    "    \n",
    "    # Flag high-urgency incidents that may need manual review\n",
    "    needs_review = result[\"classification\"].urgency >= 4 and result[\"impact\"].impact_score >= 7\n",
    "    \n",
    "    log_evaluation(trace_id=trace.id, name=\"combined_quality_score\", value=round(combined_quality, 2))\n",
    "    log_evaluation(trace_id=trace.id, name=\"needs_manual_review\", value=1.0 if needs_review else 0.0)\n",
    "\n",
    "print(f\"Added evaluations to {len(traces.data)} traces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Open **Domino Experiment Manager** to view:\n",
    "- Execution flow across all 4 agents\n",
    "- Inline evaluation metrics per trace\n",
    "- Aggregated statistics across the batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
